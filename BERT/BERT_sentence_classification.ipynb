{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT sentence classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47762a414275437183dd48145e4d3cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64df521a79bb476d9ae8fbbb2b8b3730",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6063cf5c000c403cba9f9153dd590a65",
              "IPY_MODEL_91b66ac38e5e4040b6b81c99c7c334dc"
            ]
          }
        },
        "64df521a79bb476d9ae8fbbb2b8b3730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6063cf5c000c403cba9f9153dd590a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14943cb0e4b742daaf2ecabf530b0613",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd0b7c49a10042d5b59c21b8e2d103d7"
          }
        },
        "91b66ac38e5e4040b6b81c99c7c334dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9dd99013b9014f8990eae8a34a9fcbaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 388kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60cb19961c7f4353a1cd1ea640a21792"
          }
        },
        "14943cb0e4b742daaf2ecabf530b0613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd0b7c49a10042d5b59c21b8e2d103d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dd99013b9014f8990eae8a34a9fcbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60cb19961c7f4353a1cd1ea640a21792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79d66c2f16b64a878e2391ca67cf3908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2b849ebc1884fb4a7f5e3b5bd8af70a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_456c3577c9d64705a4480e08b6463ff3",
              "IPY_MODEL_753c277991de4fce8722506f2407861a"
            ]
          }
        },
        "b2b849ebc1884fb4a7f5e3b5bd8af70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "456c3577c9d64705a4480e08b6463ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34e94320ec4342bc95b071cb25d3c5c9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9af65f236a914d68a9bce683dd440b17"
          }
        },
        "753c277991de4fce8722506f2407861a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be33d758054b4bf79638afaa81827ac4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 453B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df4b60d17a5a4285beedb2721d2d5778"
          }
        },
        "34e94320ec4342bc95b071cb25d3c5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9af65f236a914d68a9bce683dd440b17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be33d758054b4bf79638afaa81827ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df4b60d17a5a4285beedb2721d2d5778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "477e43af47524e9393c6a7b45bd56c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2270ff1b96ea4eef844d2b14d4793627",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51fac5bfd2594cbcb96312895bda0527",
              "IPY_MODEL_570a2069c6014c89a568c61ae3f172ce"
            ]
          }
        },
        "2270ff1b96ea4eef844d2b14d4793627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51fac5bfd2594cbcb96312895bda0527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8bbb206ad1f4e70afe51476a37cd84f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb6ee0dc520c42518c4fc600e09cea10"
          }
        },
        "570a2069c6014c89a568c61ae3f172ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70129a850240476388830459f1023b58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 65.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_608006bf22584273a36426e279fc979c"
          }
        },
        "c8bbb206ad1f4e70afe51476a37cd84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb6ee0dc520c42518c4fc600e09cea10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70129a850240476388830459f1023b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "608006bf22584273a36426e279fc979c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pastatimes/Master-Thesis-HateSpeech-Twitter/blob/master/BERT_sentence_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkVwQtd-kMv9",
        "colab_type": "code",
        "outputId": "63ddf679-5000-46b3-d9a3-ca5507faf4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGEWfqYMhFpm",
        "colab_type": "text"
      },
      "source": [
        "**Using Colab GPU for training**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-yXjIDOk7yG",
        "colab_type": "code",
        "outputId": "8190c9b6-3a5a-47f8-e755-f182e348f8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# source: https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP#scrollTo=DEfSbAA4QHas\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-nmyU5BlaQM",
        "colab_type": "code",
        "outputId": "ae324aaf-e12d-4518-84fb-ca128cd8662b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q5Ow0iIhV9l",
        "colab_type": "text"
      },
      "source": [
        "**Installing Hugging face library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26iVb1L8lp7j",
        "colab_type": "code",
        "outputId": "9c2d587d-9ec2-4a64-8ee4-d035df375c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 17.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b95dddaf9a24e30bcf481f15ec28e4f4f0ca03a76797e8dc7255e42f1b6c99b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y106XgPhgld",
        "colab_type": "text"
      },
      "source": [
        "**Loading Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-eB5JeDl79t",
        "colab_type": "code",
        "outputId": "5fa8699a-9eee-4090-e209-9992c2c93af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = '/content/drive/My Drive/Annotated tweets/2020-2.xls'\n",
        "data = pd.read_excel(filename)\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gg_id</th>\n",
              "      <th>text</th>\n",
              "      <th>intent.id</th>\n",
              "      <th>intent.name</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A2ac338e0</td>\n",
              "      <td>Asian Americans are VERY angry at what China h...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-12-05 11:19:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ef9e3fbf3</td>\n",
              "      <td>.@CBS and their show @60Minutes are doing ever...</td>\n",
              "      <td>HateSpeech</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-10-05 23:25:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>G33efcef2</td>\n",
              "      <td>We are getting great marks for the handling of...</td>\n",
              "      <td>HateSpeech</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-10-05 11:48:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ib6c34b77</td>\n",
              "      <td>MSDNC and FAKE NEWS CNN are going wild trying ...</td>\n",
              "      <td>OffensiveLanguage</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-04-05 22:35:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ud7f5e93c</td>\n",
              "      <td>Mexico is sadly experiencing very big CoronaVi...</td>\n",
              "      <td>OffensiveLanguage</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-04-05 13:42:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>V5f3b8de7</td>\n",
              "      <td>The Fake News Media and their Democrat Partner...</td>\n",
              "      <td>OffensiveLanguage</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 16:09:17</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>X9078b256</td>\n",
              "      <td>The Democrats and the Fake News are trying to ...</td>\n",
              "      <td>OffensiveLanguage</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:47:16</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Q0ba10a09</td>\n",
              "      <td>The Fake News Media and their Democrat Partner...</td>\n",
              "      <td>OffensiveLanguage</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:42:46</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>R5f86562b</td>\n",
              "      <td>Where have the Radical Left Do Nothing Democra...</td>\n",
              "      <td>OffensiveLanguage</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-11-01 14:07:00</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Z430b13d6</td>\n",
              "      <td>Iran is talking very boldly about targeting ce...</td>\n",
              "      <td>HateSpeech</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-04-01 22:52:00</td>\n",
              "      <td>1210000000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        gg_id  ...               id_str\n",
              "0   A2ac338e0  ...  1260000000000000000\n",
              "1   Ef9e3fbf3  ...  1260000000000000000\n",
              "2   G33efcef2  ...  1260000000000000000\n",
              "3   Ib6c34b77  ...  1260000000000000000\n",
              "4   Ud7f5e93c  ...  1260000000000000000\n",
              "..        ...  ...                  ...\n",
              "67  V5f3b8de7  ...  1220000000000000000\n",
              "68  X9078b256  ...  1220000000000000000\n",
              "69  Q0ba10a09  ...  1220000000000000000\n",
              "70  R5f86562b  ...  1220000000000000000\n",
              "71  Z430b13d6  ...  1210000000000000000\n",
              "\n",
              "[72 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh5fjqepsH_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choose the colomn on which you want to train the model\n",
        "class_of_interest = 'intent.id'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oWR7EFJWqKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labelTrans(row):\n",
        "  if row[class_of_interest] == 'Neutral':\n",
        "    return 0\n",
        "  if row[class_of_interest] == 'OffensiveLanguage':\n",
        "    return 1\n",
        "  if row[class_of_interest] == 'HateSpeech':\n",
        "    return 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgP4SriFXSPg",
        "colab_type": "code",
        "outputId": "60e708c8-b869-47ea-9f62-983e6ebc0b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "data[class_of_interest] = data.apply(lambda row: labelTrans(row), axis=1)\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gg_id</th>\n",
              "      <th>text</th>\n",
              "      <th>intent.id</th>\n",
              "      <th>intent.name</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A2ac338e0</td>\n",
              "      <td>Asian Americans are VERY angry at what China h...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-12-05 11:19:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ef9e3fbf3</td>\n",
              "      <td>.@CBS and their show @60Minutes are doing ever...</td>\n",
              "      <td>2</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-10-05 23:25:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>G33efcef2</td>\n",
              "      <td>We are getting great marks for the handling of...</td>\n",
              "      <td>2</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-10-05 11:48:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ib6c34b77</td>\n",
              "      <td>MSDNC and FAKE NEWS CNN are going wild trying ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-04-05 22:35:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ud7f5e93c</td>\n",
              "      <td>Mexico is sadly experiencing very big CoronaVi...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-04-05 13:42:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>V5f3b8de7</td>\n",
              "      <td>The Fake News Media and their Democrat Partner...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 16:09:17</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>X9078b256</td>\n",
              "      <td>The Democrats and the Fake News are trying to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:47:16</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Q0ba10a09</td>\n",
              "      <td>The Fake News Media and their Democrat Partner...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:42:46</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>R5f86562b</td>\n",
              "      <td>Where have the Radical Left Do Nothing Democra...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-11-01 14:07:00</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Z430b13d6</td>\n",
              "      <td>Iran is talking very boldly about targeting ce...</td>\n",
              "      <td>2</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-04-01 22:52:00</td>\n",
              "      <td>1210000000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        gg_id  ...               id_str\n",
              "0   A2ac338e0  ...  1260000000000000000\n",
              "1   Ef9e3fbf3  ...  1260000000000000000\n",
              "2   G33efcef2  ...  1260000000000000000\n",
              "3   Ib6c34b77  ...  1260000000000000000\n",
              "4   Ud7f5e93c  ...  1260000000000000000\n",
              "..        ...  ...                  ...\n",
              "67  V5f3b8de7  ...  1220000000000000000\n",
              "68  X9078b256  ...  1220000000000000000\n",
              "69  Q0ba10a09  ...  1220000000000000000\n",
              "70  R5f86562b  ...  1220000000000000000\n",
              "71  Z430b13d6  ...  1210000000000000000\n",
              "\n",
              "[72 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7MdYAvOsgIi",
        "colab_type": "code",
        "outputId": "8308f9e3-e699-48a7-c8c2-0f50590e97c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#clean file\n",
        "data = data.dropna()\n",
        "\n",
        "# label to interger\n",
        "data[class_of_interest] = data[class_of_interest].astype(int)\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gg_id</th>\n",
              "      <th>text</th>\n",
              "      <th>intent.id</th>\n",
              "      <th>intent.name</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A2ac338e0</td>\n",
              "      <td>Asian Americans are VERY angry at what China h...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-12-05 11:19:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ef9e3fbf3</td>\n",
              "      <td>.@CBS and their show @60Minutes are doing ever...</td>\n",
              "      <td>2</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-10-05 23:25:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>G33efcef2</td>\n",
              "      <td>We are getting great marks for the handling of...</td>\n",
              "      <td>2</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-10-05 11:48:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ib6c34b77</td>\n",
              "      <td>MSDNC and FAKE NEWS CNN are going wild trying ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-04-05 22:35:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ud7f5e93c</td>\n",
              "      <td>Mexico is sadly experiencing very big CoronaVi...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-04-05 13:42:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>V5f3b8de7</td>\n",
              "      <td>The Fake News Media and their Democrat Partner...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 16:09:17</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>X9078b256</td>\n",
              "      <td>The Democrats and the Fake News are trying to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:47:16</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Q0ba10a09</td>\n",
              "      <td>The Fake News Media and their Democrat Partner...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:42:46</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>R5f86562b</td>\n",
              "      <td>Where have the Radical Left Do Nothing Democra...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-11-01 14:07:00</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Z430b13d6</td>\n",
              "      <td>Iran is talking very boldly about targeting ce...</td>\n",
              "      <td>2</td>\n",
              "      <td>Hate Speech</td>\n",
              "      <td>2020-04-01 22:52:00</td>\n",
              "      <td>1210000000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        gg_id  ...               id_str\n",
              "0   A2ac338e0  ...  1260000000000000000\n",
              "1   Ef9e3fbf3  ...  1260000000000000000\n",
              "2   G33efcef2  ...  1260000000000000000\n",
              "3   Ib6c34b77  ...  1260000000000000000\n",
              "4   Ud7f5e93c  ...  1260000000000000000\n",
              "..        ...  ...                  ...\n",
              "67  V5f3b8de7  ...  1220000000000000000\n",
              "68  X9078b256  ...  1220000000000000000\n",
              "69  Q0ba10a09  ...  1220000000000000000\n",
              "70  R5f86562b  ...  1220000000000000000\n",
              "71  Z430b13d6  ...  1210000000000000000\n",
              "\n",
              "[72 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sha5djQt7i_Y",
        "colab_type": "code",
        "outputId": "14535d62-97a5-476d-9701-c9a14e84a3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# exploring the data\n",
        "data[class_of_interest].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    37\n",
              "1    23\n",
              "2    12\n",
              "Name: intent.id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJt4ntOu4ZFF",
        "colab_type": "code",
        "outputId": "391c1ba7-188a-4aa2-99e3-9018ce746e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "#Extract training and test data from one file\n",
        "import numpy as np\n",
        "\n",
        "shuffled = data.sample(frac=1)\n",
        "result = np.array_split(shuffled, 10) \n",
        "test_data = result[0]\n",
        "train_data = pd.concat([result[1], result[2], result[3], result[4], result[5], result[6], result[7], result[8], result[9]])\n",
        "train_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gg_id</th>\n",
              "      <th>text</th>\n",
              "      <th>intent.id</th>\n",
              "      <th>intent.name</th>\n",
              "      <th>created_at</th>\n",
              "      <th>id_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Ib9febffe</td>\n",
              "      <td>Australiaâ€™s Central Bank cut interest rates ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-03-03 06:34:00</td>\n",
              "      <td>1230000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Pba11a5cd</td>\n",
              "      <td>Just had a long and very good conversation by ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-07-02 10:31:00</td>\n",
              "      <td>1230000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Ad2977ffa</td>\n",
              "      <td>The @nytimes story is a Fake just like the â€œ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>04-13-2020 01:09:56</td>\n",
              "      <td>1250000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>F41dd1a4a</td>\n",
              "      <td>The @nytimes story is a Fake just like the â€œ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>04-13-2020 02:08:16</td>\n",
              "      <td>1250000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>X73b06b8f</td>\n",
              "      <td>Australiaâ€™s Central Bank cut interest rates ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-03-03 06:27:00</td>\n",
              "      <td>1230000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Yd0c66325</td>\n",
              "      <td>Working closely with China and others on Coron...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>01-30-2020 22:04:35</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>X9078b256</td>\n",
              "      <td>The Democrats and the Fake News are trying to ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>01-13-2020 15:47:16</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>E45e3b476</td>\n",
              "      <td>....Fake News got it wrong again as always and...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-03-05 20:18:00</td>\n",
              "      <td>1260000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>R5f86562b</td>\n",
              "      <td>Where have the Radical Left Do Nothing Democra...</td>\n",
              "      <td>1</td>\n",
              "      <td>Offensive Language</td>\n",
              "      <td>2020-11-01 14:07:00</td>\n",
              "      <td>1220000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>D200bd33a</td>\n",
              "      <td>The food is GREAT at Sammyâ€™s Mexican Grill i...</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>2020-01-03 15:11:00</td>\n",
              "      <td>1230000000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        gg_id  ...               id_str\n",
              "41  Ib9febffe  ...  1230000000000000000\n",
              "52  Pba11a5cd  ...  1230000000000000000\n",
              "17  Ad2977ffa  ...  1250000000000000000\n",
              "16  F41dd1a4a  ...  1250000000000000000\n",
              "42  X73b06b8f  ...  1230000000000000000\n",
              "..        ...  ...                  ...\n",
              "55  Yd0c66325  ...  1220000000000000000\n",
              "68  X9078b256  ...  1220000000000000000\n",
              "5   E45e3b476  ...  1260000000000000000\n",
              "70  R5f86562b  ...  1220000000000000000\n",
              "44  D200bd33a  ...  1230000000000000000\n",
              "\n",
              "[64 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_K2afRE8r09",
        "colab_type": "code",
        "outputId": "3d22a78e-5d66-4fb3-b1ee-8ee1a9e25c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Check if the training dataset is not significantly different from the whole dataset\n",
        "train_data[class_of_interest].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    34\n",
              "1    21\n",
              "2     9\n",
              "Name: intent.id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ_T14ILh3xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = train_data['text'].values\n",
        "labels = train_data[class_of_interest].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2NJM2ZWoRl_",
        "colab_type": "text"
      },
      "source": [
        "**Tokenization & Input Formatting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJh-D9AonQmj",
        "colab_type": "code",
        "outputId": "14818fe1-a1d4-4135-9eed-814e6e97b22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "47762a414275437183dd48145e4d3cb1",
            "64df521a79bb476d9ae8fbbb2b8b3730",
            "6063cf5c000c403cba9f9153dd590a65",
            "91b66ac38e5e4040b6b81c99c7c334dc",
            "14943cb0e4b742daaf2ecabf530b0613",
            "cd0b7c49a10042d5b59c21b8e2d103d7",
            "9dd99013b9014f8990eae8a34a9fcbaf",
            "60cb19961c7f4353a1cd1ea640a21792"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47762a414275437183dd48145e4d3cb1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX3r6CbwrHCJ",
        "colab_type": "code",
        "outputId": "8777fd03-b6b8-499d-a6c0-e5610452f38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgSL2LKnp-wJ",
        "colab_type": "code",
        "outputId": "7b9f2a4a-540d-4921-f02e-0a0673cd69be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 88,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Australiaâ€™s Central Bank cut interest rates and stated it will most likely further ease in order to make up for Chinaâ€™s Coronavirus situation and slowdown. They reduced to 0.5% a record low. Other countries are doing the same thing if not more so. Our Federal Reserve has us....\n",
            "Token IDs: tensor([  101,  2660,  2050, 30102, 30108,  2015,  2430,  2924,  3013,  3037,\n",
            "         6165,  1998,  3090,  2009,  2097,  2087,  3497,  2582,  7496,  1999,\n",
            "         2344,  2000,  2191,  2039,  2005,  2859,  2050, 30102, 30108,  2015,\n",
            "        21887, 23350,  3663,  1998,  4030,  7698,  1012,  2027,  4359,  2000,\n",
            "         1014,  1012,  1019,  1003,  1037,  2501,  2659,  1012,  2060,  3032,\n",
            "         2024,  2725,  1996,  2168,  2518,  2065,  2025,  2062,  2061,  1012,\n",
            "         2256,  2976,  3914,  2038,  2149,  1012,  1012,  1012,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lyrwry0rxFO",
        "colab_type": "code",
        "outputId": "dd5ab203-ce15-41e2-c9af-37dbad334cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   57 training samples\n",
            "    7 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrO0Z4L6r2pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGX2JFrHr5oz",
        "colab_type": "code",
        "outputId": "35e94781-72f1-414d-efe9-81553821f122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "79d66c2f16b64a878e2391ca67cf3908",
            "b2b849ebc1884fb4a7f5e3b5bd8af70a",
            "456c3577c9d64705a4480e08b6463ff3",
            "753c277991de4fce8722506f2407861a",
            "34e94320ec4342bc95b071cb25d3c5c9",
            "9af65f236a914d68a9bce683dd440b17",
            "be33d758054b4bf79638afaa81827ac4",
            "df4b60d17a5a4285beedb2721d2d5778",
            "477e43af47524e9393c6a7b45bd56c85",
            "2270ff1b96ea4eef844d2b14d4793627",
            "51fac5bfd2594cbcb96312895bda0527",
            "570a2069c6014c89a568c61ae3f172ce",
            "c8bbb206ad1f4e70afe51476a37cd84f",
            "eb6ee0dc520c42518c4fc600e09cea10",
            "70129a850240476388830459f1023b58",
            "608006bf22584273a36426e279fc979c"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79d66c2f16b64a878e2391ca67cf3908",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "477e43af47524e9393c6a7b45bd56c85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SGfbZMVsAow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxk_2XogsNdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ISHKWPBsQFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def get_f1_score(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return f1_score(pred_flat, labels_flat, average=\"macro\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CHrK4C9sTU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u3QJrSor3LS",
        "colab_type": "code",
        "outputId": "a5683398-c487-4f4f-9757-7ba8929af83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 20 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    total_eval_f1 = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        total_eval_f1 += get_f1_score(logits, label_ids)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_f1 = total_eval_f1 / len(validation_dataloader)\n",
        "    print(\"  F1 score: {0:.2f}\".format(avg_f1))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'F1 Score': avg_f1,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.01\n",
            "  Training epcoh took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.29\n",
            "  F1 score: 0.15\n",
            "  Validation Loss: 1.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.98\n",
            "  Training epcoh took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.29\n",
            "  F1 score: 0.15\n",
            "  Validation Loss: 1.19\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.92\n",
            "  Training epcoh took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.29\n",
            "  F1 score: 0.15\n",
            "  Validation Loss: 1.20\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.92\n",
            "  Training epcoh took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.29\n",
            "  F1 score: 0.15\n",
            "  Validation Loss: 1.21\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:03 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1kzWwF71sVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = []\n",
        "f1.append([d['F1 Score'] for d in training_stats])\n",
        "\n",
        "accuracy = []\n",
        "accuracy.append([d['Valid. Accur.'] for d in training_stats])\n",
        "\n",
        "loss = []\n",
        "loss.append([d['Training Loss'] for d in training_stats])\n",
        "\n",
        "epoch = []\n",
        "epoch.append([d['epoch'] for d in training_stats])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWbZHjkWt5S6",
        "colab_type": "code",
        "outputId": "6457395d-e1d8-43a4-a552-6c3624fb290a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(epoch, loss, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZpoVQcf6tT4",
        "colab_type": "code",
        "outputId": "bda3ce8b-6b30-4075-d661-09edee3ff11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "n_epochs = range(1,11)\n",
        "x = epochs\n",
        "y = [loss[0], accuracy[0[0]], f1]\n",
        "\n",
        "for name, metric in zip(['Loss', 'Accuracy', 'F1'], y):\n",
        "    _ = plt.plot(metric, label = name)\n",
        "    _ = plt.xlabel('Epochs')\n",
        "    _ = plt.ylabel('Score')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab_type": "code",
        "outputId": "da32aa67-477f-401d-8b16-d5c8547bc348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = test_data\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df['text'].values\n",
        "labels = df[class_of_interest].values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16 \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab_type": "code",
        "outputId": "69e01b11-5c69-4205-881d-e377cd3753ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Calculate the accuracy for this batch of test sentences.\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "  tmp_eval_f1 = get_f1_score(logits, label_ids)\n",
        "  # Accumulate the total accuracy.\n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  eval_f1 += tmp_eval_f1\n",
        "\n",
        "  # Track the number of batches\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"  F1 score: {0:.2f}\".format(eval_f1/nb_eval_steps))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8a4f37bee583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prediction on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicting labels for {:,} test sentences...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Put model in evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prediction_inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_GX7PZNDOh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = 0\n",
        "pred_list = []\n",
        "for b in range(0,len(prediction_dataloader)-1):\n",
        "  for i in range(0,batch_size):\n",
        "    pred_dict = {}\n",
        "    pred_dict['label'] = labels[s]\n",
        "    pred_dict['check'] = true_labels[b][i]\n",
        "    pred_dict['sentence'] = sentences[s]\n",
        "    \n",
        "    temp = tf.round(tf.nn.softmax(predictions[b][i]))\n",
        "\n",
        "    if int(temp[0].numpy()) == 1:\n",
        "      pred_dict['prediction'] = 0\n",
        "\n",
        "    if int(temp[1].numpy()) == 1:\n",
        "      pred_dict['prediction'] = 1\n",
        "\n",
        "    if int(temp[2].numpy()) == 1:\n",
        "      pred_dict['prediction'] = 2\n",
        "\n",
        "    if int(temp[3].numpy()) == 1:\n",
        "      pred_dict['prediction'] = 3\n",
        "\n",
        "    if pred_dict['prediction'] == pred_dict['label']:\n",
        "      pred_dict['correct'] = 'yes'\n",
        "    else:\n",
        "      pred_dict['correct'] = 'no'\n",
        "\n",
        "  \n",
        "    pred_list.append(pred_dict)\n",
        "    s = s + 1\n",
        "\n",
        "pred_df = pd.DataFrame(pred_list)\n",
        "pred_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZuLmC-jhC99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_df['correct'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgvUbvaghYCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = pred_df.loc[pred_df['correct'] == 'no']\n",
        "temp.to_csv('/path/filename.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgYZj_Uv8P5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egvOOgmgCaLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP3mb52uET--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}